{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import math"
      ],
      "metadata": {
        "id": "z7WAAZ2bBIK-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4JKgXejrBEOD"
      },
      "outputs": [],
      "source": [
        "# Function to count and print the number of each digit in the dataset\n",
        "def print_digit_distribution(y, label=\"Distribution\"):\n",
        "    digit_counts = np.sum(y, axis=0)\n",
        "    print(f\"{label}:\")\n",
        "    for i, count in enumerate(digit_counts):\n",
        "        print(f\"Digit {i}: {int(count)}\")\n",
        "    print()  # Add an extra line for better readability\n",
        "\n",
        "def introduce_bias(x_train, y_train, digit_to_reduce, reduction_percentage):\n",
        "    # Find indices of the digit to reduce\n",
        "    indices_of_digit = np.where(np.argmax(y_train, axis=1) == digit_to_reduce)[0]\n",
        "\n",
        "    reduction_percentage = 1 - reduction_percentage\n",
        "    # Randomly select a subset of the digit to remove\n",
        "    np.random.shuffle(indices_of_digit)\n",
        "    indices_to_remove = indices_of_digit[len(indices_of_digit) * reduction_percentage // 100:]\n",
        "\n",
        "    # Initialize lists to store filtered data\n",
        "    biased_x_train = []\n",
        "    biased_y_train = []\n",
        "\n",
        "    # Iterate through the original training data\n",
        "    for i in range(len(x_train)):\n",
        "        # Check if the current index is not in indices_to_remove\n",
        "        if i not in indices_to_remove:\n",
        "            # If not, append the corresponding data to the filtered lists\n",
        "            biased_x_train.append(x_train[i])\n",
        "            biased_y_train.append(y_train[i])\n",
        "\n",
        "    # Convert the filtered lists to numpy arrays\n",
        "    return np.array(biased_x_train), np.array(biased_y_train)\n",
        "\n",
        "\n",
        "def visualize_examples(model, x_test, y_test, num_examples=25, figsize=(10, 10), fontsize=10):\n",
        "    # Predictions on test set\n",
        "    predictions = model.predict(x_test)\n",
        "\n",
        "    # Visualize examples\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(num_examples):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        plt.imshow(x_test[i], cmap='gray')\n",
        "        plt.title(f\"True: {np.argmax(y_test[i])}, Predicted: {np.argmax(predictions[i])}\", fontsize=fontsize)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_misclassifications(model, x_test, y_test):\n",
        "    # Obtain the predictions and the true classes\n",
        "    predictions = np.argmax(model.predict(x_test), axis=-1)\n",
        "    true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Identify misclassified indices\n",
        "    misclassified_indices = np.where(predictions != true_classes)[0]\n",
        "\n",
        "    # Extract the true labels of misclassified images\n",
        "    misclassified_true_labels = true_classes[misclassified_indices]\n",
        "\n",
        "    # Count the number of misclassified instances for each digit\n",
        "    misclassified_counts = np.zeros(10)\n",
        "    for label in misclassified_true_labels:\n",
        "        misclassified_counts[label] += 1\n",
        "\n",
        "    # Create a bar chart\n",
        "    digits = np.arange(10)  # Array of digits from 0 to 9\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(digits, misclassified_counts, color='red')\n",
        "    plt.xlabel('Digits')\n",
        "    plt.ylabel('Number of Misclassifications')\n",
        "    plt.xticks(digits)\n",
        "    plt.title('Number of Misclassified Instances for Each Digit')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "    # Evaluate the model on the test dataset\n",
        "    loss, accuracy = model.evaluate(x_test, y_test)\n",
        "    print(\"Test Loss:\", loss)\n",
        "    print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "def plot_confusion_matrix(model, x_test, y_test):\n",
        "    # Generate predictions\n",
        "    predictions = np.argmax(model.predict(x_test), axis=-1)\n",
        "    true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(true_classes, predictions)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1,2,3,4,5,6,7,8,9], yticklabels=[0,1,2,3,4,5,6,7,8,9])\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def print_misclassified_images(model, x_test, y_test, num_images=100):\n",
        "    # Generate predictions for the specified number of images in the test set\n",
        "    predictions = model.predict(x_test[:num_images])\n",
        "\n",
        "    # Convert predictions to class numbers\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Convert true labels from one-hot encoding to class numbers\n",
        "    true_classes = np.argmax(y_test[:num_images], axis=1)\n",
        "\n",
        "    # Identify the indices of misclassified images within the specified number of predictions\n",
        "    misclassified_indices = np.where(predicted_classes != true_classes)[0]\n",
        "\n",
        "    print(f\"Total misclassified images in first {num_images} predictions: {len(misclassified_indices)}\")\n",
        "\n",
        "    # Plot the misclassified images\n",
        "    for i, misclassified_index in enumerate(misclassified_indices):\n",
        "        plt.figure(figsize=(2, 2))\n",
        "        plt.imshow(x_test[misclassified_index].reshape(28, 28), cmap='gray')\n",
        "        plt.title(f\"Predicted: {predicted_classes[misclassified_index]}, True: {true_classes[misclassified_index]}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def print_misclassified_images_by_label_in_grid(model, x_test, y_test, true_label, num_images=100):\n",
        "    # Generate predictions for the specified number of images in the test set\n",
        "    predictions = model.predict(x_test[:num_images])\n",
        "\n",
        "    # Convert predictions to class numbers\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Convert true labels from one-hot encoding to class numbers\n",
        "    true_classes = np.argmax(y_test[:num_images], axis=1)\n",
        "\n",
        "    # Identify the indices of misclassified images within the specified number of predictions\n",
        "    misclassified_indices = np.where((predicted_classes != true_classes) & (true_classes == true_label))[0]\n",
        "\n",
        "    print(f\"Total misclassified images of true label {true_label} in first {num_images} predictions: {len(misclassified_indices)}\")\n",
        "\n",
        "    # Determine the size of the grid\n",
        "    num_misclassified = len(misclassified_indices)\n",
        "    grid_size = math.ceil(math.sqrt(num_misclassified))\n",
        "\n",
        "    # Create a figure with subplots in a square or nearly square layout\n",
        "    plt.figure(figsize=(grid_size * 2, grid_size * 2))\n",
        "    for i, misclassified_index in enumerate(misclassified_indices):\n",
        "        plt.subplot(grid_size, grid_size, i + 1)\n",
        "        plt.imshow(x_test[misclassified_index].reshape(28, 28), cmap='gray')  # Adjust the reshape dimensions as per your dataset\n",
        "        plt.title(f\"Pred: {predicted_classes[misclassified_index]}, True: {true_classes[misclassified_index]}\", fontsize=10)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Cut the input dataset to only half of thier values\n",
        "half_index = len(x_train) // 2\n",
        "\n",
        "x_train = x_train[:half_index]\n",
        "y_train = y_train[:half_index]\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=2,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "print(\"Running the model prior to introducing a bias in the training set.\")\n",
        "\n",
        "# Evaluating model\n",
        "evaluate_model(model, x_test, y_test)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "plot_confusion_matrix(model, x_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "PGYruVY1stWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze misclassifications for each digit\n",
        "plot_misclassifications(model, x_test, y_test)\n",
        "\n",
        "# Visualize predictions for the test set\n",
        "visualize_examples(model, x_test, y_test, num_examples=25)"
      ],
      "metadata": {
        "id": "V75Vu-wR1oza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Print original dataset distribution\n",
        "print_digit_distribution(y_train, label=\"Original Dataset Distribution\")\n",
        "\n",
        "# Introduce bias (reduce occurrences of digit '8' by 50%)\n",
        "biased_x_train, biased_y_train = introduce_bias(x_train, y_train, digit_to_reduce=8, reduction_percentage=50)\n",
        "\n",
        "# Print biased dataset distribution\n",
        "print_digit_distribution(biased_y_train, label=\"Biased Dataset Distribution\")\n",
        "\n",
        "# Define CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the biased dataset\n",
        "model.fit(biased_x_train, biased_y_train, epochs=2, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Evaluating model\n",
        "evaluate_model(model, x_test, y_test)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "plot_confusion_matrix(model, x_test, y_test)\n",
        "\n",
        "# Analyze misclassifications for each digit\n",
        "plot_misclassifications(model, x_test, y_test)\n",
        "\n",
        "# Visualize predictions for the test set\n",
        "visualize_examples(model, x_test, y_test, num_examples=25)\n",
        "\n",
        "\n",
        "print_misclassified_images(model, x_test, y_test, num_images=100)\n",
        "\n",
        "# Visualize misclassified images for a specific digit (e.g., digit 8)\n",
        "print_misclassified_images_by_label_in_grid(model, x_test, y_test, true_label=8, num_images=100)"
      ],
      "metadata": {
        "id": "TNZ4Dz8hbUKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SGqJqtEMdJvN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}